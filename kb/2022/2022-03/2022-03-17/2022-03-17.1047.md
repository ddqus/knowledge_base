# Thoughts on using Producer instance as a singleton

```
google:confluent "python" kafka producer thread safe
#kafka #producer #singleton #fatal
```

* kafka producer 를 a) singleton 으로 사용할 것인가? b) 생성 - 메시징 - 삭제 방식으로 반복해서 생성할 것인가?


* singleton 으로 사용하는 것이 좋다. producer 인스턴스 생성은 비싼 작업이기 때문에 반복 생성은 추천하지 않는다.
    * (카프카 공식 팀의 답변이니 신뢰할 수 있다)
* singleton 방식이 반복 생성 방식에 비해 500,000배 정도 효율적이다.
* singleton 방식일 경우, connection 관리는 어떻게 되는가? 첫 생성 후 broker 와의 접속을 계속 유지해야 하는가?
    * broker 는 일정 시간동안 사용하지 않은 connection 은 kill 한다.(디폴트 10분)
    * broker 는 connnection 을 종료하더라도 요청을 받으면 다시 connection 을 맺는다.
* singleton 방식일 경우, producer 가 메시지를 produce 하는 과정에서 예외가 발생하면 어떻게 되는가? 예외가 발생한 producer 를 제거하고 다시 생성해야 하는가?
    * https://github.com/edenhill/librdkafka/blob/master/INTRODUCTION.md#fatal-producer-errors
    * 흔하지 않은, 매우 예외적인 상황에서 발생한다.
* fatal 에러를 어떻게 감지할 수 있는가? aws lambda 같이 생명주기를 통제할 수 없는 환경의 경우에는 producer 에러에 어떻게 대응해야 하는가?
    * fatal 에러가 발생하면 예외의 Error 프로퍼티의 IsFatal 플래그의 값이 true 가 된다.
    * fatal 에러가 발생할 경우 SetErrorHandler 를 통해 이벤트를 받을 수 있다.
    * 멱등적인 producer 를 사용하지 않는다면, fatal 에러는 발생하지 않는다.
    * lambda 같은 환경의 경우, manager 객체를 생성해서 manager 객체가 producer 를 생성하고, 문제가 있을 경우 kill and restart 하는 방식을 추천한다.
* consumer 는 어떠한가? producer 와 비슷한가?
    * consumer 비슷하게 생성하는 것이 좋다. consumer pool 을 추천한다.

> https://github.com/confluentinc/confluent-kafka-dotnet/issues/1346
>
> https://github.com/confluentinc/confluent-kafka-dotnet/issues/159
